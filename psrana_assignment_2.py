# -*- coding: utf-8 -*-
"""PSRANA_Assignment_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11EcqxKBBhXEuJQAXJx2GHBl6VHcckwZ5
"""

!pip install simpy xgboost seaborn

import simpy
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time

from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor

from xgboost import XGBRegressor

def bank_simulation(arrival_rate, service_rate, num_servers, sim_time):

    env = simpy.Environment()
    server = simpy.Resource(env, capacity=num_servers)
    wait_times = []

    def customer(env):
        arrival_time = env.now
        with server.request() as req:
            yield req
            wait_times.append(env.now - arrival_time)
            service_time = random.expovariate(service_rate)
            yield env.timeout(service_time)

    def arrival_process(env):
        while True:
            yield env.timeout(random.expovariate(arrival_rate))
            env.process(customer(env))

    env.process(arrival_process(env))
    env.run(until=sim_time)

    return np.mean(wait_times) if wait_times else 0

data = []

for _ in range(1000):

    arrival = random.uniform(1, 20)
    service = random.uniform(1, 15)
    servers = random.randint(1, 5)
    sim_time = random.randint(100, 500)

    avg_wait = bank_simulation(arrival, service, servers, sim_time)

    data.append([arrival, service, servers, sim_time, avg_wait])

df = pd.DataFrame(data, columns=[
    "arrival_rate",
    "service_rate",
    "num_servers",
    "simulation_time",
    "avg_wait_time"
])

df.head()

plt.figure(figsize=(8,6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

X = df.drop("avg_wait_time", axis=1)
y = df["avg_wait_time"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

models = {
    "Linear Regression": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(),
    "ElasticNet": ElasticNet(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Extra Trees": ExtraTreesRegressor(random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42),
    "AdaBoost": AdaBoostRegressor(random_state=42),
    "XGBoost": XGBRegressor(random_state=42, verbosity=0),
    "KNN": KNeighborsRegressor(),
    "MLP Regressor": MLPRegressor(max_iter=1000, random_state=42)
}

kf = KFold(n_splits=5, shuffle=True, random_state=42)

results = []

for name, model in models.items():

    start = time.time()

    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')
    mean_cv = np.mean(cv_scores)

    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    mse = mean_squared_error(y_test, preds)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    end = time.time()

    results.append([
        name,
        mean_cv,
        r2,
        rmse,
        mae,
        end - start
    ])

results_df = pd.DataFrame(results, columns=[
    "Model",
    "CV Mean R2",
    "Test R2",
    "RMSE",
    "MAE",
    "Training Time (sec)"
])

results_df.sort_values(by="Test R2", ascending=False)

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5]
}

grid = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)

grid.fit(X_train, y_train)

best_rf = grid.best_estimator_

print("Best Parameters:", grid.best_params_)

preds = best_rf.predict(X_test)

print("Tuned RF R2:", r2_score(y_test, preds))
print("Tuned RF RMSE:", np.sqrt(mean_squared_error(y_test, preds)))

importances = best_rf.feature_importances_

importance_df = pd.DataFrame({
    "Feature": X.columns,
    "Importance": importances
}).sort_values(by="Importance", ascending=False)

plt.figure(figsize=(8,5))
plt.bar(importance_df["Feature"], importance_df["Importance"])
plt.xticks(rotation=45)
plt.title("Feature Importance (Random Forest)")
plt.show()

importance_df

sorted_df = results_df.sort_values(by="Test R2", ascending=False)

plt.figure(figsize=(10,6))
plt.bar(sorted_df["Model"], sorted_df["Test R2"])
plt.xticks(rotation=75)
plt.ylabel("R2 Score")
plt.title("Model Comparison")
plt.show()

plt.scatter(y_test, preds)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted (Best Model)")
plt.show()

